# 3.2 - –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ETL/ELT: dbt, Airflow, Informatica

## –í–≤–µ–¥–µ–Ω–∏–µ

–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ETL/ELT –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å–ª–æ–∂–Ω—ã—Ö –∫–∞—Å—Ç–æ–º–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ.

## üìä –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

| –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç             | –¢–∏–ø            | –ú–æ–¥–µ–ª—å   | –Ø–∑—ã–∫     | –õ—É—á—à–µ–µ –¥–ª—è             |
| ---------------------- | -------------- | -------- | -------- | ---------------------- |
| **dbt**                | Transformation | ELT      | SQL      | Data transformation    |
| **Airflow**            | Orchestration  | Workflow | Python   | Pipeline orchestration |
| **Informatica**        | Enterprise ETL | ETL/ELT  | GUI/Java | Enterprise integration |
| **Azure Data Factory** | Cloud ETL      | ETL/ELT  | GUI/.NET | Azure ecosystem        |
| **Talend**             | Hybrid ETL     | ETL/ELT  | Java/GUI | Data integration       |

---

## üõ†Ô∏è **dbt (Data Build Tool)**

### **–§–∏–ª–æ—Å–æ—Ñ–∏—è**

- "Transformation as code"
- SQL-—Ü–µ–Ω—Ç—Ä–∏—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥
- Version control –∏ testing
- Documentation generation

### **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**

```bash
dbt Core + dbt Cloud
‚îú‚îÄ‚îÄ Models: SQL transformations
‚îú‚îÄ‚îÄ Tests: Data quality checks
‚îú‚îÄ‚îÄ Documentation: Auto-generated docs
‚îî‚îÄ‚îÄ Macros: Reusable SQL components
```

### **–ü—Ä–∏–º–µ—Ä —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞ C#**

```csharp
public class DbtService
{
    private readonly IDbtRunner _dbtRunner;

    public async Task RunDbtTransformationsAsync(string environment)
    {
        // dbt —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É
        var result = await _dbtRunner.ExecuteAsync(new DbtCommand
        {
            Command = "dbt run",
            Profile = environment,
            Target = "prod",
            Select = "tag:daily",
            FullRefresh = false
        });

        if (result.Success)
        {
            await RunDbtTestsAsync();
            await GenerateDocumentationAsync();
        }
    }

    public async Task<bool> ValidateDataQualityAsync()
    {
        var testResult = await _dbtRunner.ExecuteAsync(new DbtCommand
        {
            Command = "dbt test",
            Profile = "prod"
        });

        return testResult.Success && testResult.FailedTests == 0;
    }
}

// –ü—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ dbt –º–æ–¥–µ–ª–µ–π –∏–∑ C#
public class DbtModelGenerator
{
    public string GenerateStagingModel(string sourceTable, string[] columns)
    {
        return $@"
            {{{
                config(
                    materialized='view',
                    tags=['staging', 'daily']
                )
            }}}

            SELECT
                {string.Join(",\n                ", columns.Select(c => $"{c} as {c.ToLower()}"))}
            FROM {{{{ source('raw_sources', '{sourceTable}') }}}}
            WHERE _loaded_at >= CURRENT_DATE - 1";
    }

    public string GenerateFactModel(string name, string[] dimensions, string[] measures)
    {
        return $@"
            {{{
                config(
                    materialized='incremental',
                    unique_key='{name}_key',
                    on_schema_change='fail'
                )
            }}}

            SELECT
                {string.Join(",\n                ", dimensions)},
                {string.Join(",\n                ", measures)}
            FROM {{{{ ref('stg_{name}') }}}}
            {% if is_incremental() %}
            WHERE _loaded_at > (SELECT MAX(_loaded_at) FROM {{{{ this }}}})
            {% endif %}";
    }
}
```

### **dbt Testing Framework**

```csharp
public class DbtTestGenerator
{
    public string GenerateUniqueTest(string modelName, string column)
    {
        return $@"
            -- tests/unique_{modelName}_{column}.sql
            {{%
                test unique(model=ref('{modelName}'), column_name='{column}')
            %}}
                SELECT {column}
                FROM {{{{ model }}}}
                GROUP BY {column}
                HAVING COUNT(*) > 1
            {{% endtest %}}";
    }

    public string GenerateRelationshipTest(string modelName, string column, string parentModel)
    {
        return $@"
            -- tests/relationships/{modelName}_{column}.sql
            {{%
                test relationships(
                    model=ref('{modelName}'),
                    column_name='{column}',
                    to=ref('{parentModel}'),
                    field='{column}'
                )
            %}}
                SELECT child.{column}
                FROM {{{{ model }}}} as child
                LEFT JOIN {{{{ ref('{parentModel}') }}}} as parent
                    ON child.{column} = parent.{column}
                WHERE parent.{column} IS NULL
            {{% endtest %}}";
    }
}
```

---

## üîÑ **Apache Airflow**

### **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**

```bash
Airflow Architecture
‚îú‚îÄ‚îÄ Scheduler: Task orchestration
‚îú‚îÄ‚îÄ Executor: Task execution
‚îú‚îÄ‚îÄ Webserver: UI
‚îîÔ∏è‚îÄ‚îÄ Metadata DB: State storage
```

### **–ü—Ä–∏–º–µ—Ä DAG –Ω–∞ C#-–ø–æ–¥–æ–±–Ω–æ–º —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–µ**

```csharp
// Conceptual representation of Airflow DAG in C# style
public class DataProcessingDag
{
    [Dag(
        dagId = "daily_data_pipeline",
        scheduleInterval = "0 2 * * *",
        startDate = "2024-01-01",
        catchup = false
    )]
    public async Task ExecuteDailyPipelineAsync()
    {
        // Extract tasks
        var extractSales = new PythonOperator(
            taskId: "extract_sales_data",
            pythonCallable: "extract_sales_from_api",
            opKwargs: new { date = "{{ ds }}" }
        );

        var extractCustomers = new PythonOperator(
            taskId: "extract_customer_data",
            pythonCallable: "extract_customers_from_db"
        );

        // Transform tasks
        var transformSales = new PythonOperator(
            taskId: "transform_sales_data",
            pythonCallable: "clean_and_transform_sales"
        );

        var transformCustomers = new PythonOperator(
            taskId: "transform_customer_data",
            pythonCallable: "enrich_customer_data"
        );

        // Load tasks
        var loadToDwh = new PythonOperator(
            taskId: "load_to_data_warehouse",
            pythonCallable: "load_transformed_data"
        );

        // Data quality checks
        var dataQualityCheck = new PythonOperator(
            taskId: "data_quality_validation",
            pythonCallable: "run_data_quality_tests"
        );

        // Define dependencies
        extractSales >> transformSales;
        extractCustomers >> transformCustomers;

        [BranchPythonOperator(taskId = "check_quality")]
        public string QualityCheckBranch()
        {
            var qualityPassed = RunQualityChecks();
            return qualityPassed ? "load_to_dwh" : "send_failure_alert";
        }

        [PythonOperator(taskId = "send_failure_alert")]
        public void SendFailureAlert()
        {
            // Send alert on data quality failure
            SendSlackAlert("Data quality checks failed!");
        }
    }
}
```

### **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Airflow —Å C#**

```csharp
public class AirflowIntegrationService
{
    private readonly IAirflowApiClient _airflowClient;

    public async Task<string> TriggerDagAsync(string dagId, Dictionary<string, object> config = null)
    {
        var response = await _airflowClient.TriggerDagAsync(dagId, new DagRun
        {
            Conf = config,
            ExecutionDate = DateTime.UtcNow
        });

        return response.DagRunId;
    }

    public async Task<DagRunStatus> GetDagStatusAsync(string dagId, string runId)
    {
        return await _airflowClient.GetDagRunStatusAsync(dagId, runId);
    }

    public async Task<bool> WaitForDagCompletionAsync(string dagId, string runId, TimeSpan timeout)
    {
        var startTime = DateTime.UtcNow;

        while (DateTime.UtcNow - startTime < timeout)
        {
            var status = await GetDagStatusAsync(dagId, runId);

            if (status == DagRunStatus.Success)
                return true;
            if (status == DagRunStatus.Failed)
                return false;

            await Task.Delay(TimeSpan.FromSeconds(30));
        }

        throw new TimeoutException($"DAG {dagId} run {runId} did not complete within timeout");
    }
}
```

---

## üè¢ **Informatica PowerCenter**

### **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**

```bash
Informatica Architecture
‚îú‚îÄ‚îÄ Repository: Metadata storage
‚îú‚îÄ‚îÄ Integration Service: Execution engine
‚îú‚îÄ‚îÄ Designer: Development tool
‚îîÔ∏è‚îÄ‚îÄ Workflow Manager: Orchestration
```

### **–ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å C#**

```csharp
public class InformaticaIntegrationService
{
    private readonly IInformaticaClient _informaticaClient;

    public async Task<WorkflowExecutionResult> ExecuteInformaticaWorkflowAsync(
        string workflowName,
        Dictionary<string, string> parameters)
    {
        // Start workflow execution
        var executionId = await _informaticaClient.StartWorkflowAsync(
            workflowName, parameters);

        // Monitor execution
        var status = await MonitorWorkflowExecutionAsync(executionId);

        // Get execution details
        var details = await _informaticaClient.GetWorkflowDetailsAsync(executionId);

        return new WorkflowExecutionResult
        {
            ExecutionId = executionId,
            Status = status,
            Details = details,
            Success = status == WorkflowStatus.Completed
        };
    }

    public async Task<MappingConfiguration> GenerateSalesMappingAsync()
    {
        // Programmatic mapping configuration
        var mapping = new MappingConfiguration
        {
            Name = "MAP_SALES_TRANSFORM",
            SourceConnection = "SRC_SALES_DB",
            TargetConnection = "TGT_DWH"
        };

        // Source definition
        mapping.Source = new SourceDefinition
        {
            Name = "SALES_TRANSACTIONS",
            Query = "SELECT * FROM sales_transactions WHERE transaction_date >= ?"
        };

        // Transformations
        mapping.Transformations.Add(new ExpressionTransformation
        {
            Name = "EXP_CALCULATE_NET_SALES",
            Expression = "SALES_AMOUNT - DISCOUNT_AMOUNT"
        });

        mapping.Transformations.Add(new LookupTransformation
        {
            Name = "LKP_CUSTOMER_DETAILS",
            LookupSource = "DIM_CUSTOMER",
            JoinCondition = "CUSTOMER_ID = CUSTOMER_KEY"
        });

        // Target definition
        mapping.Target = new TargetDefinition
        {
            Name = "FACT_SALES",
            LoadOrder = 1,
            UpdateStrategy = UpdateStrategy.Insert
        };

        return mapping;
    }
}
```

---

## üîÑ **Azure Data Factory**

### **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**

```bash
ADF Architecture
‚îú‚îÄ‚îÄ Pipeline: Workflow definition
‚îú‚îÄ‚îÄ Activities: Processing steps
‚îú‚îÄ‚îÄ Datasets: Data structures
‚îîÔ∏è‚îÄ‚îÄ Linked Services: Connections
```

### **–ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å C#**

```csharp
public class DataFactoryService
{
    private readonly DataFactoryManagementClient _adfClient;

    public async Task<string> CreateDataPipelineAsync(PipelineDefinition pipelineDef)
    {
        var pipeline = new PipelineResource
        {
            Activities = pipelineDef.Activities.Select(a => CreateActivity(a)).ToList(),
            Concurrency = pipelineDef.Concurrency,
            Variables = pipelineDef.Variables
        };

        var response = await _adfClient.Pipelines.CreateOrUpdateAsync(
            pipelineDef.ResourceGroup,
            pipelineDef.FactoryName,
            pipelineDef.Name,
            pipeline
        );

        return response.Name;
    }

    public async Task<PipelineRun> TriggerPipelineAsync(
        string factoryName,
        string pipelineName,
        Dictionary<string, object> parameters)
    {
        var runResponse = await _adfClient.Pipelines.CreateRunAsync(
            _resourceGroup, factoryName, pipelineName, parameters: parameters);

        // Monitor pipeline execution
        return await MonitorPipelineRunAsync(factoryName, runResponse.RunId);
    }

    private async Task<PipelineRun> MonitorPipelineRunAsync(string factoryName, string runId)
    {
        PipelineRun run;
        do
        {
            run = await _adfClient.PipelineRuns.GetAsync(_resourceGroup, factoryName, runId);
            await Task.Delay(TimeSpan.FromSeconds(15));
        }
        while (run.Status == "InProgress" || run.Status == "Queued");

        return run;
    }
}

// –ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–∏—è ADF pipeline –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ
public class SalesDataPipelineBuilder
{
    public PipelineDefinition BuildSalesPipeline()
    {
        return new PipelineDefinition
        {
            Name = "PL_SALES_DAILY_LOAD",
            Activities = new List<PipelineActivity>
            {
                new CopyActivity
                {
                    Name = "CopySalesFromSource",
                    Source = new SqlSource { SqlReaderQuery = "SELECT * FROM sales" },
                    Sink = new AzureSqlSink { TableName = "stg_sales" }
                },
                new StoredProcedureActivity
                {
                    Name = "TransformSalesData",
                    StoredProcedureName = "usp_TransformSales"
                },
                new DataQualityActivity
                {
                    Name = "ValidateDataQuality",
                    ValidationRules = GetDataQualityRules()
                }
            }
        };
    }
}
```

---

## üéØ **–ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤**

### **–í—ã–±–∏—Ä–∞–π—Ç–µ dbt –µ—Å–ª–∏:**

- ‚úÖ ELT –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –º–æ—â–Ω—ã–º Cloud DWH
- ‚úÖ –ö–æ–º–∞–Ω–¥–∞ —Å–∏–ª—å–Ω–∞ –≤ SQL
- ‚úÖ –¢—Ä–µ–±—É–µ—Ç—Å—è version control –∏ testing
- ‚úÖ Data transformation –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ

### **–í—ã–±–∏—Ä–∞–π—Ç–µ Airflow –µ—Å–ª–∏:**

- ‚úÖ –°–ª–æ–∂–Ω–∞—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è multiple systems
- ‚úÖ Python-based —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
- ‚úÖ –¢—Ä–µ–±—É–µ—Ç—Å—è –≥–∏–±–∫–æ—Å—Ç—å –∏ –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è
- ‚úÖ Open-source —Ä–µ—à–µ–Ω–∏–µ

### **–í—ã–±–∏—Ä–∞–π—Ç–µ Informatica –µ—Å–ª–∏:**

- ‚úÖ Enterprise-–æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å strict governance
- ‚úÖ GUI-based —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–æ–±–ª–∞–¥–∞–µ—Ç
- ‚úÖ –°–ª–æ–∂–Ω–∞—è data integration
- ‚úÖ –¢—Ä–µ–±—É–µ—Ç—Å—è enterprise support

### **–í—ã–±–∏—Ä–∞–π—Ç–µ ADF –µ—Å–ª–∏:**

- ‚úÖ Azure ecosystem
- ‚úÖ Low-code/no-code –ø–æ–¥—Ö–æ–¥
- ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Microsoft stack
- ‚úÖ Managed service —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

---

## üîß **–ì–∏–±—Ä–∏–¥–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã**

### **dbt + Airflow –∫–æ–º–±–∏–Ω–∞—Ü–∏—è**

```csharp
public class DbtAirflowOrchestration
{
    public async Task ExecuteDataPipelineAsync()
    {
        // Airflow –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏
        var dagRunId = await _airflowService.TriggerDagAsync("daily_data_pipeline");

        // –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        var status = await _airflowService.WaitForDagCompletionAsync(
            "daily_data_pipeline", dagRunId, TimeSpan.FromHours(2));

        if (status)
        {
            // dbt –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
            await _dbtService.RunDbtTransformationsAsync("prod");

            // Data quality checks
            var qualityPassed = await _dbtService.ValidateDataQualityAsync();

            if (!qualityPassed)
            {
                throw new DataQualityException("Data quality checks failed after dbt run");
            }
        }
    }
}
```

---

## üìä **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**

| –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç      | –í—Ä–µ–º—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ | –°—Ç–æ–∏–º–æ—Å—Ç—å  | –ì–∏–±–∫–æ—Å—Ç—å   | –ü–æ–¥–¥–µ—Ä–∂–∫–∞ enterprise |
| --------------- | ---------------- | ---------- | ---------- | -------------------- |
| **dbt**         | üü¢ –ë—ã—Å—Ç—Ä–æ–µ       | üü¢ –ù–∏–∑–∫–∞—è  | üü¢ –í—ã—Å–æ–∫–∞—è | üü° –°—Ä–µ–¥–Ω—è—è           |
| **Airflow**     | üü° –°—Ä–µ–¥–Ω–µ–µ       | üü¢ –ù–∏–∑–∫–∞—è  | üü¢ –í—ã—Å–æ–∫–∞—è | üü° –°—Ä–µ–¥–Ω—è—è           |
| **Informatica** | üî¥ –ú–µ–¥–ª–µ–Ω–Ω–æ–µ     | üî¥ –í—ã—Å–æ–∫–∞—è | üü° –°—Ä–µ–¥–Ω—è—è | üü¢ –í—ã—Å–æ–∫–∞—è           |
| **ADF**         | üü° –°—Ä–µ–¥–Ω–µ–µ       | üü° –°—Ä–µ–¥–Ω—è—è | üü° –°—Ä–µ–¥–Ω—è—è | üü¢ –í—ã—Å–æ–∫–∞—è           |

---

## üö® **Anti-patterns**

1. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Airflow –¥–ª—è data transformation** - –Ω–µ –µ–≥–æ –æ—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞
2. **dbt –±–µ–∑ proper orchestration** - –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ end-to-end —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
3. **Enterprise tools –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö use cases** - over-engineering
4. **Ignoring team skillset** –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

---

## ‚úÖ **Best Practices**

### **–î–ª—è dbt:**

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ modular model design
- –†–µ–∞–ª–∏–∑—É–π—Ç–µ comprehensive testing
- –ì–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ tags –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π

### **–î–ª—è Airflow:**

- –°–æ–∑–¥–∞–π—Ç–µ reusable components
- –†–µ–∞–ª–∏–∑—É–π—Ç–µ proper error handling
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ XCom –¥–ª—è –º–µ–∂—Ç–∞—Å–∫–æ–≤–æ–≥–æ –æ–±–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã–º–∏
- –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ performance DAG-–æ–≤

### **–î–ª—è –≤—Å–µ—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤:**

- –†–µ–∞–ª–∏–∑—É–π—Ç–µ version control –¥–ª—è –≤—Å–µ—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
- –°–æ–∑–¥–∞–π—Ç–µ CI/CD pipelines –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ data lineage
- –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ performance –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å

---

**–°–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑–¥–µ–ª:** [3.3 - –û–Ω-–ø—Ä–µ–º–∏—Å —Ä–µ—à–µ–Ω–∏—è: Teradata, Exadata, ClickHouse](./03-on-prem-solutions.md)
